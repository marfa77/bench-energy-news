"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –≤–µ–±-—Å–∞–π—Ç —á–µ—Ä–µ–∑ GitHub Pages.
–°–æ–∑–¥–∞–µ—Ç HTML —Ñ–∞–π–ª—ã, –æ–±–Ω–æ–≤–ª—è–µ—Ç sitemap.xml –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Google Indexing API.
"""
import os
import json
import subprocess
import requests
import logging
from pathlib import Path
from typing import Optional, Dict, Tuple
from datetime import datetime
from urllib.parse import quote
from dotenv import load_dotenv

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
LOG_DIR = Path(__file__).parent / "logs"
LOG_DIR.mkdir(exist_ok=True)

# –§–∞–π–ª –¥–ª—è –ª–æ–≥–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
PUBLISH_LOG_FILE = LOG_DIR / "web_publish.log"
ERROR_LOG_FILE = LOG_DIR / "web_publish_errors.log"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
publish_logger = logging.getLogger("web_publisher")
publish_logger.setLevel(logging.DEBUG)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ–±—â–µ–≥–æ –ª–æ–≥–∞ (INFO –∏ –≤—ã—à–µ)
publish_handler = logging.FileHandler(PUBLISH_LOG_FILE, encoding='utf-8')
publish_handler.setLevel(logging.INFO)
publish_formatter = logging.Formatter(
    '%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
publish_handler.setFormatter(publish_formatter)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ—à–∏–±–æ–∫ (ERROR –∏ –≤—ã—à–µ)
error_handler = logging.FileHandler(ERROR_LOG_FILE, encoding='utf-8')
error_handler.setLevel(logging.ERROR)
error_formatter = logging.Formatter(
    '%(asctime)s | ERROR | %(message)s\n%(exc_info)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
error_handler.setFormatter(error_formatter)

# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
if not publish_logger.handlers:
    publish_logger.addHandler(publish_handler)
    publish_logger.addHandler(error_handler)

def log_info(message: str):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
    print(message)
    publish_logger.info(message)

def log_error(message: str, exc_info=None):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É"""
    print(f"‚ùå {message}")
    publish_logger.error(message, exc_info=exc_info)

def log_warning(message: str):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"""
    print(f"‚ö†Ô∏è  {message}")
    publish_logger.warning(message)

def log_success(message: str):
    """–õ–æ–≥–∏—Ä—É–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ"""
    print(f"‚úÖ {message}")
    publish_logger.info(f"SUCCESS: {message}")

# GitHub Pages –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# –î–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –û–¢–î–ï–õ–¨–ù–´–ô —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
NEWS_REPO_PATH = os.getenv("NEWS_REPO_PATH")  # –ü—É—Ç—å –∫ –æ—Ç–¥–µ–ª—å–Ω–æ–º—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π
GITHUB_REPO_PATH = os.getenv("GITHUB_REPO_PATH", NEWS_REPO_PATH or ".")  # Fallback –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
GITHUB_REPO_URL = os.getenv("GITHUB_REPO_URL")  # URL —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –¥–ª—è push
GITHUB_BRANCH = os.getenv("GITHUB_BRANCH", "main")  # –í–µ—Ç–∫–∞ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")  # Personal Access Token –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ push
SITE_URL = os.getenv("SITE_URL", "https://bench.energy")  # URL —Å–∞–π—Ç–∞ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π

# Google Indexing API
# –ü—É—Ç—å –∫ –∫–ª—é—á—É –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º (–æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞) –∏–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
GOOGLE_INDEXING_KEY_PATH = os.getenv("GOOGLE_INDEXING_KEY_PATH", "google-indexing-key.json")


def create_slug(title: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç URL-friendly slug –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞.
    
    Args:
        title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏
        
    Returns:
        Slug –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ URL
    """
    import re
    # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
    title = re.sub(r'<[^>]+>', '', title)
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –¥–µ—Ñ–∏—Å—ã, —É–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    slug = re.sub(r'[^\w\s-]', '', title.lower())
    slug = re.sub(r'[-\s]+', '-', slug)
    slug = slug.strip('-')
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    if len(slug) > 80:
        slug = slug[:80].rstrip('-')
    return slug


def create_ai_summary(news_title: str, news_summary: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ AI Summary –¥–ª—è –±–ª–æ–∫–∞ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç–∞—Ç—å–∏.
    
    Args:
        news_title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏
        news_summary: –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
        
    Returns:
        AI Summary –≤ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
    """
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ summary –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    sentences = news_summary.split('. ')
    if len(sentences) >= 2:
        summary = '. '.join(sentences[:2])
        if not summary.endswith('.'):
            summary += '.'
    else:
        summary = news_summary[:200] + '...' if len(news_summary) > 200 else news_summary
    
    return summary


def create_schema_org_markup(news_data: Dict, article_url: str, html_content: str = "") -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é Schema.org —Ä–∞–∑–º–µ—Ç–∫—É NewsArticle –¥–ª—è SEO –∏ LLM.
    
    Args:
        news_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç–∏
        article_url: URL –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏
        html_content: HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–∞—Ç—å–∏ (–¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
        
    Returns:
        JSON-LD —Ä–∞–∑–º–µ—Ç–∫–∞
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
    try:
        from seo_optimizer import generate_enhanced_schema_org
        return generate_enhanced_schema_org(news_data, article_url, html_content)
    except ImportError:
        # Fallback –Ω–∞ –±–∞–∑–æ–≤—É—é –≤–µ—Ä—Å–∏—é
        pass
    
    # –ë–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è (fallback)
    schema = {
        "@context": "https://schema.org",
        "@type": "NewsArticle",
        "headline": news_data.get("title", ""),
        "description": news_data.get("summary", ""),
        "datePublished": datetime.now().isoformat(),
        "dateModified": datetime.now().isoformat(),
        "author": {
            "@type": "Organization",
            "name": "Bench Energy",
            "url": "https://t.me/benchenergy",
            "sameAs": [
                "https://t.me/benchenergy",
                article_url
            ]
        },
        "publisher": {
            "@type": "Organization",
            "name": "Bench Energy",
            "url": "https://t.me/benchenergy",
            "logo": {
                "@type": "ImageObject",
                "url": f"{SITE_URL}/assets/bench-energy-logo.png"
            },
            "sameAs": [
                "https://t.me/benchenergy"
            ]
        },
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": article_url
        },
        "articleSection": news_data.get("category", "Coal"),
        "keywords": "coal market, energy news, thermal coal, coking coal, freight, shipping, Bench Energy, Telegram channel @benchenergy",
        "breadcrumb": {
            "@type": "BreadcrumbList",
            "itemListElement": [
                {
                    "@type": "ListItem",
                    "position": 1,
                    "name": "Home",
                    "item": f"{SITE_URL}/"
                },
                {
                    "@type": "ListItem",
                    "position": 2,
                    "name": "News",
                    "item": f"{SITE_URL}/posts/"
                },
                {
                    "@type": "ListItem",
                    "position": 3,
                    "name": news_data.get("title", "")[:50],
                    "item": article_url
                }
            ]
        }
    }
    
    if news_data.get("source_url"):
        schema["sameAs"] = [news_data["source_url"], "https://t.me/benchenergy"]
    else:
        schema["sameAs"] = ["https://t.me/benchenergy"]
    
    return json.dumps(schema, indent=2, ensure_ascii=False)


def create_html_article(news_data: Dict, web_version: str, image_url: Optional[str] = None, published_date: Optional[datetime] = None) -> Tuple[str, str, str]:
    """
    –°–æ–∑–¥–∞–µ—Ç HTML —à–∞–±–ª–æ–Ω –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏ —Å SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.
    
    Args:
        news_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç–∏
        web_version: HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–∞—Ç—å–∏
        image_url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        published_date: –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–µ–∫—É—â–∞—è –¥–∞—Ç–∞)
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (html_content, article_url, slug)
    """
    title = news_data.get("title", "")
    summary = news_data.get("summary", "")
    source_url = news_data.get("source_url", "")
    source_name = news_data.get("source_name", "Unknown")
    category = news_data.get("category", "Coal")
    
    # –°–æ–∑–¥–∞–µ–º AI Summary
    ai_summary = create_ai_summary(title, summary)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è OpenGraph
    og_image = image_url or f"{SITE_URL}/assets/default-news.jpg"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –¥–∞—Ç—É –∏–ª–∏ —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
    if published_date is None:
        published_date = datetime.now()
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    pub_date = published_date.strftime("%Y-%m-%dT%H:%M:%S+00:00")
    pub_date_display = published_date.strftime("%B %d, %Y")
    
    # –°–æ–∑–¥–∞–µ–º slug –¥–ª—è URL
    slug = create_slug(title)
    article_url = f"{SITE_URL}/posts/{slug}.html"
    
    # Schema.org —Ä–∞–∑–º–µ—Ç–∫–∞ (—Å —É–ª—É—á—à–µ–Ω–Ω–æ–π SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π)
    schema_markup = create_schema_org_markup(news_data, article_url, web_version)
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML –≤ title –∏ summary –¥–ª—è –º–µ—Ç–∞-—Ç–µ–≥–æ–≤
    import html
    title_escaped = html.escape(title)
    summary_escaped = html.escape(summary[:200])
    
    html_template = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title_escaped} | Bench Energy</title>
    <meta name="description" content="{summary_escaped[:160]}">
    <meta name="keywords" content="coal market, energy news, thermal coal, coking coal, freight, shipping, Bench Energy, @benchenergy, Telegram channel">
    <meta name="author" content="Bench Energy">
    <link rel="canonical" href="{article_url}">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="{article_url}">
    <meta property="og:title" content="{title_escaped}">
    <meta property="og:description" content="{summary_escaped}">
    <meta property="og:image" content="{og_image}">
    <meta property="og:site_name" content="Bench Energy">
    <meta property="article:author" content="Bench Energy">
    <meta property="article:published_time" content="{pub_date}">
    <meta property="article:modified_time" content="{pub_date}">
    <meta property="article:section" content="{category}">
    
    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="{article_url}">
    <meta name="twitter:title" content="{title_escaped}">
    <meta name="twitter:description" content="{summary_escaped}">
    <meta name="twitter:image" content="{og_image}">
    
    <!-- Schema.org JSON-LD -->
    <script type="application/ld+json">
    {schema_markup}
    </script>
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F55Q439F8J"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){{dataLayer.push(arguments);}}
      gtag('js', new Date());

      gtag('config', 'G-F55Q439F8J');
    </script>
    
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }}
        .answer-capsule {{
            background: #f0f7ff;
            border-left: 4px solid #0066cc;
            padding: 1.25rem;
            margin: 2rem 0;
            border-radius: 4px;
            font-size: 1.05rem;
            line-height: 1.7;
        }}
        .answer-capsule p {{
            margin: 0;
            color: #1a1a1a;
        }}
        .header {{
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }}
        .header h1 {{
            margin: 0 0 10px 0;
            font-size: 2em;
            color: #1a1a1a;
        }}
        .meta {{
            color: #666;
            font-size: 0.9em;
            margin-bottom: 20px;
        }}
        .ai-summary {{
            background: #f0f9f4;
            border-left: 4px solid #22c55e;
            border-radius: 8px;
            padding: 1.25rem 1.5rem;
            margin: 1.5rem 0;
            font-size: 0.95rem;
            line-height: 1.7;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }}
        .ai-summary b {{
            color: #22c55e;
            font-weight: 700;
            font-size: 1rem;
        }}
        .content {{
            margin: 30px 0;
        }}
        .content h2 {{
            color: #1a1a1a;
            margin-top: 30px;
        }}
        .content p {{
            margin: 15px 0;
        }}
        .source-link {{
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
        }}
        .source-link a {{
            color: #1976D2;
            text-decoration: none;
        }}
        .source-link a:hover {{
            text-decoration: underline;
        }}
        .telegram-link {{
            display: inline-block;
            margin-top: 20px;
            padding: 10px 20px;
            background: #0088cc;
            color: white;
            text-decoration: none;
            border-radius: 5px;
        }}
        .telegram-link:hover {{
            background: #006ba3;
        }}
        .category-badge {{
            display: inline-block;
            padding: 5px 10px;
            background: #e3f2fd;
            color: #1976D2;
            border-radius: 3px;
            font-size: 0.85em;
            margin-bottom: 10px;
        }}
        img {{
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 20px 0;
        }}
    </style>
</head>
<body>
    <div class="header">
        <span class="category-badge">{category}</span>
        <h1>{title}</h1>
        <div class="meta">
            Published: {pub_date_display} | Bench Energy
        </div>
    </div>
    
    <div class="ai-summary">
        <b>AI Summary:</b> {ai_summary}
    </div>
    
    {f'<img src="{image_url}" alt="{title_escaped}" />' if image_url else ''}
    
    <div class="content">
        {web_version}
    </div>
    
    <div class="source-link">
        <strong>Source:</strong> <a href="{source_url}" target="_blank" rel="noopener noreferrer">{source_name}</a>
    </div>
    
    <div style="margin-top: 40px; padding: 20px; background: #f5f5f5; border-radius: 8px;">
        <h3 style="margin-top: 0;">üì± Follow Bench Energy on Telegram</h3>
        <p>Get the latest coal market news and analysis directly in your Telegram:</p>
        <a href="https://t.me/benchenergy" class="telegram-link" target="_blank" rel="noopener noreferrer">
            üì± Join @benchenergy Channel
        </a>
        <p style="margin-top: 15px; font-size: 0.9em; color: #666;">
            Bench Energy provides daily updates on coal markets, freight rates, and energy industry news. 
            Follow our Telegram channel <strong>@benchenergy</strong> for real-time market insights.
        </p>
    </div>
</body>
</html>"""
    
    return html_template, article_url, slug


def update_sitemap(article_url: str, slug: str, repo_path: str):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç sitemap.xml, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—É—é —Å—Ç–∞—Ç—å—é.
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º sitemap.xml, –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –µ–≥–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é.
    
    Args:
        article_url: URL —Å—Ç–∞—Ç—å–∏
        slug: Slug —Å—Ç–∞—Ç—å–∏
        repo_path: –ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é
    """
    sitemap_path = Path(repo_path) / "sitemap.xml"
    posts_dir = Path(repo_path) / "posts"
    posts_dir.mkdir(exist_ok=True)
    
    # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π sitemap –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
    if sitemap_path.exists():
        print(f"   ‚ÑπÔ∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π sitemap.xml, –æ–±–Ω–æ–≤–ª—è—é...")
        try:
            with open(sitemap_path, 'r', encoding='utf-8') as f:
                sitemap_content = f.read()
        except:
            sitemap_content = """<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
</urlset>"""
    else:
        sitemap_content = """<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
</urlset>"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç—Ç–∞ —Å—Ç–∞—Ç—å—è –≤ sitemap
    if article_url not in sitemap_content:
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
        lastmod = datetime.now().strftime("%Y-%m-%d")
        new_entry = f"""  <url>
    <loc>{article_url}</loc>
    <lastmod>{lastmod}</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>"""
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º —Ç–µ–≥–æ–º, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if "</urlset>" in sitemap_content:
            sitemap_content = sitemap_content.replace("</urlset>", new_entry + "\n</urlset>")
        else:
            # –ï—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º —Ç–µ–≥–æ–º
            sitemap_content = sitemap_content.rstrip() + "\n" + new_entry + "\n</urlset>"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        try:
            with open(sitemap_path, 'w', encoding='utf-8') as f:
                f.write(sitemap_content)
            log_info(f"Sitemap –æ–±–Ω–æ–≤–ª–µ–Ω: {article_url}")
        except Exception as e:
            log_error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è sitemap: {e}", exc_info=True)
    else:
        log_info(f"–°—Ç–∞—Ç—å—è —É–∂–µ –µ—Å—Ç—å –≤ sitemap, –ø—Ä–æ–ø—É—Å–∫–∞—é")


def git_add_commit_push(repo_path: str, files: list, commit_message: str):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª—ã –≤ Git, –∫–æ–º–º–∏—Ç–∏—Ç –∏ –ø—É—à–∏—Ç.
    
    Args:
        repo_path: –ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é
        files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        commit_message: –°–æ–æ–±—â–µ–Ω–∏–µ –∫–æ–º–º–∏—Ç–∞
        
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –∏–Ω–∞—á–µ
    """
    try:
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        original_cwd = os.getcwd()
        os.chdir(repo_path)
        
        # Git add
        # –§–∞–π–ª—ã —É–∂–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏ –æ—Ç –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        repo_path_obj = Path(repo_path)
        for file_path in files:
            # –ï—Å–ª–∏ –ø—É—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–π, –¥–µ–ª–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º
            if os.path.isabs(file_path):
                try:
                    rel_path = os.path.relpath(file_path, repo_path_obj)
                except ValueError:
                    # –ï—Å–ª–∏ —Ñ–∞–π–ª –≤–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    rel_path = file_path
            else:
                # –£–∂–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
                rel_path = file_path
            
            result = subprocess.run(
                ["git", "add", rel_path],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                log_warning(f"git add {rel_path}: {result.stderr}")
            else:
                log_info(f"git add {rel_path}")
        
        # Git commit
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º [ci skip] –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç, —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ GitHub Pages
        if "[ci skip]" not in commit_message and "[skip ci]" not in commit_message:
            commit_message = f"{commit_message} [ci skip]"
        log_info(f"–®–ê–ì 8.2: –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–º–∏—Ç–∞...")
        result = subprocess.run(
            ["git", "commit", "-m", commit_message],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode != 0:
            if "nothing to commit" in result.stdout or "nothing to commit" in result.stderr:
                log_warning("–ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∫–æ–º–º–∏—Ç–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–∫–æ–º–º–∏—á–µ–Ω—ã)")
                log_info(f"   stdout: {result.stdout}")
                log_info(f"   stderr: {result.stderr}")
                os.chdir(original_cwd)
                return True  # –≠—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞, –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π
            else:
                log_error(f"–û—à–∏–±–∫–∞ git commit: {result.stderr}")
                log_error(f"   stdout: {result.stdout}")
                os.chdir(original_cwd)
                return False
        
        log_success(f"–ö–æ–º–º–∏—Ç —Å–æ–∑–¥–∞–Ω: {commit_message}")
        
        # Git pull –ø–µ—Ä–µ–¥ push –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        log_info(f"–®–ê–ì 8.2.5: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º (pull)...")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –¥–µ–ª–∞–µ–º stash –¥–ª—è –Ω–µ–æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
        stash_result = subprocess.run(
            ["git", "stash", "--include-untracked"],
            capture_output=True,
            text=True,
            timeout=10,
            env={**os.environ, "GIT_TERMINAL_PROMPT": "0"}
        )
        
        pull_result = subprocess.run(
            ["git", "pull", "--rebase", "origin", GITHUB_BRANCH],
            capture_output=True,
            text=True,
            timeout=30,
            env={**os.environ, "GIT_TERMINAL_PROMPT": "0"}
        )
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º stash (–µ—Å–ª–∏ –±—ã–ª —Å–æ–∑–¥–∞–Ω)
        if stash_result.returncode == 0:
            subprocess.run(
                ["git", "stash", "pop"],
                capture_output=True,
                text=True,
                timeout=10,
                env={**os.environ, "GIT_TERMINAL_PROMPT": "0"}
            )
        
        if pull_result.returncode != 0:
            if "fatal: couldn't find remote ref" in pull_result.stderr:
                log_warning("–í–µ—Ç–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (–≤–æ–∑–º–æ–∂–Ω–æ, –ø–µ—Ä–≤–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è)")
            elif "Already up to date" in pull_result.stdout or "Already up to date" in pull_result.stderr:
                log_info("   –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–∂–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω")
            elif "could not detach HEAD" in pull_result.stderr or "would be overwritten" in pull_result.stderr:
                log_warning("–ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã –ø—Ä–∏ pull (–ø—Ä–æ–ø—É—Å–∫–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é, –ø—Ä–æ–¥–æ–ª–∂–∏–º —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º)")
            else:
                log_warning(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ git pull: {pull_result.stderr[:200]}")
        else:
            log_info("   –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º")
        
        # Git push —Å –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ —Ç–æ–∫–µ–Ω
        log_info(f"–®–ê–ì 8.3: –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ GitHub (push)...")
        if GITHUB_TOKEN:
            log_info("   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GITHUB_TOKEN –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–∫–µ–Ω –≤ URL –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            # –§–æ—Ä–º–∞—Ç: https://TOKEN@github.com/owner/repo.git
            remote_url = subprocess.run(
                ["git", "config", "--get", "remote.origin.url"],
                capture_output=True,
                text=True,
                timeout=5
            ).stdout.strip()
            log_info(f"   Remote URL: {remote_url[:50]}...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º owner/repo –∏–∑ URL
            if "github.com" in remote_url:
                # –§–æ—Ä–º–∞—Ç: https://github.com/owner/repo.git –∏–ª–∏ git@github.com:owner/repo.git
                if remote_url.startswith("https://"):
                    # –£–∂–µ HTTPS URL
                    if "@" not in remote_url:
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –≤ URL
                        remote_url_with_token = remote_url.replace(
                            "https://github.com/",
                            f"https://{GITHUB_TOKEN}@github.com/"
                        )
                    else:
                        # –¢–æ–∫–µ–Ω —É–∂–µ –µ—Å—Ç—å, –∑–∞–º–µ–Ω—è–µ–º
                        import re
                        remote_url_with_token = re.sub(
                            r"https://[^@]+@github.com/",
                            f"https://{GITHUB_TOKEN}@github.com/",
                            remote_url
                        )
                elif remote_url.startswith("git@"):
                    # SSH URL, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ HTTPS —Å —Ç–æ–∫–µ–Ω–æ–º
                    # git@github.com:owner/repo.git -> https://TOKEN@github.com/owner/repo.git
                    remote_url_with_token = remote_url.replace(
                        "git@github.com:",
                        f"https://{GITHUB_TOKEN}@github.com/"
                    ).replace(".git", ".git")
                else:
                    remote_url_with_token = remote_url
                
                # –í—Ä–µ–º–µ–Ω–Ω–æ –º–µ–Ω—è–µ–º remote URL –¥–ª—è push
                subprocess.run(
                    ["git", "remote", "set-url", "origin", remote_url_with_token],
                    capture_output=True,
                    timeout=5
                )
            
            # Push —Å —Ç–æ–∫–µ–Ω–æ–º
            result = subprocess.run(
                ["git", "push", "origin", GITHUB_BRANCH],
                capture_output=True,
                text=True,
                timeout=30,
                env={**os.environ, "GIT_TERMINAL_PROMPT": "0"}  # –û—Ç–∫–ª—é—á–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            )
        else:
            # Push –±–µ–∑ —Ç–æ–∫–µ–Ω–∞ (–º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏)
            log_warning("GITHUB_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, push –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            result = subprocess.run(
                ["git", "push", "origin", GITHUB_BRANCH],
                capture_output=True,
                text=True,
                timeout=30
            )
        
        if result.returncode != 0:
            error_msg = f"–û—à–∏–±–∫–∞ git push: {result.stderr}"
            log_error(error_msg)
            log_error(f"   stdout: {result.stdout}")
            if "Authentication failed" in result.stderr or "fatal: could not read Username" in result.stderr:
                log_error("–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ GITHUB_TOKEN –≤ .env")
                log_error("–°–æ–∑–¥–∞–π—Ç–µ Personal Access Token: https://github.com/settings/tokens")
            elif "remote: Permission denied" in result.stderr or "403" in result.stderr:
                log_error("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ —Ç–æ–∫–µ–Ω–∞ GITHUB_TOKEN")
            elif "fatal: not a git repository" in result.stderr:
                log_error("–û—à–∏–±–∫–∞: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —è–≤–ª—è–µ—Ç—Å—è git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º")
            elif "fatal: could not read" in result.stderr:
                log_error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ git")
            os.chdir(original_cwd)
            return False
        
        log_success("–ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ GitHub")
        os.chdir(original_cwd)
        return True
        
    except subprocess.TimeoutExpired:
        print(f"   ‚ö†Ô∏è  –¢–∞–π–º–∞—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è git –∫–æ–º–∞–Ω–¥—ã")
        if 'original_cwd' in locals():
            os.chdir(original_cwd)
        return False
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ git –æ–ø–µ—Ä–∞—Ü–∏–π: {e}")
        if 'original_cwd' in locals():
            os.chdir(original_cwd)
        return False


def copy_image_to_assets(image_path: Path, repo_path: Path, slug: str) -> Optional[str]:
    """
    –ö–æ–ø–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ assets/ –∏–ª–∏ images/ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É–±–ª–∏—á–Ω—ã–π URL.
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≤—Ä–µ–¥–∏—Ç—å –µ—ë.
    
    Args:
        image_path: –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        repo_path: –ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é
        slug: Slug —Å—Ç–∞—Ç—å–∏ (–¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)
        
    Returns:
        –ü—É–±–ª–∏—á–Ω—ã–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not image_path or not image_path.exists():
        return None
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∞—è –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: assets/ –∏–ª–∏ images/
        assets_dir = repo_path / "assets"
        images_dir = repo_path / "images"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ø–∞–ø–∫—É –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º assets/ –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π
        if images_dir.exists() and not assets_dir.exists():
            target_dir = images_dir
            url_prefix = "images"
            print(f"   ‚ÑπÔ∏è  –ò—Å–ø–æ–ª—å–∑—É—é —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ø–∞–ø–∫—É images/")
        else:
            target_dir = assets_dir
            url_prefix = "assets"
            target_dir.mkdir(exist_ok=True)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        ext = image_path.suffix or ".jpg"
        image_filename = f"{slug}{ext}"
        dest_path = target_dir / image_filename
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º
        if dest_path.exists():
            # –î–æ–±–∞–≤–ª—è–µ–º timestamp –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            import time
            timestamp = int(time.time())
            image_filename = f"{slug}-{timestamp}{ext}"
            dest_path = target_dir / image_filename
            print(f"   ‚ö†Ô∏è  –§–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—é –∏–º—è: {image_filename}")
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
        import shutil
        shutil.copy2(image_path, dest_path)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É–±–ª–∏—á–Ω—ã–π URL
        image_url = f"{SITE_URL}/{url_prefix}/{image_filename}"
        print(f"   ‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {url_prefix}/{image_filename}")
        return image_url
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None


def publish_to_web(news_data: Dict, web_version: str, image_path: Optional[Path] = None) -> Optional[str]:
    """
    –ü—É–±–ª–∏–∫—É–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –Ω–∞ –≤–µ–±-—Å–∞–π—Ç —á–µ—Ä–µ–∑ GitHub Pages.
    
    –í–ê–ñ–ù–û: GITHUB_REPO_PATH –¥–æ–ª–∂–µ–Ω —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ö–û–†–ï–ù–¨ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–Ω–µ –Ω–∞ bot/).
    –ü–æ—Å—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ posts/ –≤ –∫–æ—Ä–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è.
    
    Args:
        news_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç–∏
        web_version: HTML –≤–µ—Ä—Å–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –≤–µ–±–∞
        image_path: –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        URL –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    news_title = news_data.get("title", "Unknown")
    news_url = news_data.get("source_url", "")
    
    log_info(f"=" * 80)
    log_info(f"üåê –ù–ê–ß–ê–õ–û –ü–£–ë–õ–ò–ö–ê–¶–ò–ò: {news_title[:60]}")
    log_info(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {news_url}")
    log_info(f"   –í—Ä–µ–º—è: {datetime.now().isoformat()}")
    
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: NEWS_REPO_PATH > GITHUB_REPO_PATH > –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        repo_path = None
    
        if NEWS_REPO_PATH:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
            repo_path = Path(NEWS_REPO_PATH).expanduser().resolve()
            log_info(f"üìÅ –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è NEWS_REPO_PATH: {repo_path}")
        elif GITHUB_REPO_PATH and GITHUB_REPO_PATH != ".":
            # Fallback –Ω–∞ GITHUB_REPO_PATH –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            repo_path = Path(GITHUB_REPO_PATH).expanduser().resolve()
            log_info(f"üìÅ –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GITHUB_REPO_PATH: {repo_path}")
        else:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ - –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è production
            log_warning("–®–ê–ì 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
            log_warning("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å NEWS_REPO_PATH –≤ .env")
            current_path = Path(__file__).parent.resolve()  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è bot/
            
            # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –≤–≤–µ—Ä—Ö –ø–æ –¥–µ—Ä–µ–≤—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, –∏—â–µ–º .git
            search_path = current_path
            for _ in range(5):  # –ú–∞–∫—Å–∏–º—É–º 5 —É—Ä–æ–≤–Ω–µ–π –≤–≤–µ—Ä—Ö
                git_dir = search_path / ".git"
                if git_dir.exists():
                    repo_path = search_path
                    log_info(f"   ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω: {repo_path}")
                    break
                if search_path.parent == search_path:  # –î–æ—Å—Ç–∏–≥–ª–∏ –∫–æ—Ä–Ω—è —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
                    break
                search_path = search_path.parent
        
        if not repo_path:
            error_msg = "–®–ê–ì 1: –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω!"
            log_error(error_msg)
            log_error("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ .env: NEWS_REPO_PATH=/absolute/path/to/news-repository")
            return None
        
        if not repo_path.exists():
            error_msg = f"–®–ê–ì 1: –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {repo_path}"
            log_error(error_msg)
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å .git –≤ –∫–æ—Ä–Ω–µ)
        git_dir = repo_path / ".git"
        if not git_dir.exists():
            error_msg = f"–®–ê–ì 1: –≠—Ç–æ –Ω–µ Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {repo_path}"
            log_error(error_msg)
            log_error("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ NEWS_REPO_PATH —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ö–û–†–ï–ù–¨ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è")
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º—ã –Ω–µ –≤ –ø–∞–ø–∫–µ bot/
        if repo_path.name == "bot":
            log_warning(f"–®–ê–ì 1: –í–ù–ò–ú–ê–ù–ò–ï: –ü—É—Ç—å —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ø–∞–ø–∫—É bot/")
            log_warning(f"   –¢–µ–∫—É—â–∏–π –ø—É—Ç—å: {repo_path}")
            log_warning(f"   –ò—Å–ø—Ä–∞–≤–ª—è—é –Ω–∞: {repo_path.parent}")
            repo_path = repo_path.parent
            log_info(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–µ–Ω—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo_path}")
        
        log_info(f"üìÅ –®–ê–ì 1: –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –æ–ø—Ä–µ–¥–µ–ª–µ–Ω: {repo_path}")
        
        # –°–æ–∑–¥–∞–µ–º slug –¥–ª—è —Å—Ç–∞—Ç—å–∏ (–Ω—É–∂–µ–Ω –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        log_info(f"üìù –®–ê–ì 2: –°–æ–∑–¥–∞–Ω–∏–µ slug –¥–ª—è —Å—Ç–∞—Ç—å–∏...")
        slug = create_slug(news_data.get("title", ""))
        log_info(f"   Slug: {slug}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_url = None
        image_file_path = None
        if image_path and image_path.exists():
            log_info(f"üñºÔ∏è  –®–ê–ì 3: –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
            log_info(f"   –ò—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å: {image_path}")
            image_url = copy_image_to_assets(image_path, repo_path, slug)
        if image_url:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ assets/ –∏–ª–∏ images/)
            assets_dir = repo_path / "assets"
            images_dir = repo_path / "images"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≤ –∫–∞–∫—É—é –ø–∞–ø–∫—É –±—ã–ª–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if images_dir.exists() and not assets_dir.exists():
                target_image_dir = images_dir
            else:
                target_image_dir = assets_dir
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL
            import re
            match = re.search(r'/([^/]+\.(jpg|jpeg|png|gif|webp))', image_url)
            if match:
                image_filename = match.group(1)
                image_file_path = target_image_dir / image_filename
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º slug
                image_filename = f"{slug}{image_path.suffix or '.jpg'}"
                image_file_path = target_image_dir / image_filename
    
            if image_url:
                log_success(f"–®–ê–ì 3: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {image_url}")
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ assets/ –∏–ª–∏ images/)
                assets_dir = repo_path / "assets"
                images_dir = repo_path / "images"
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≤ –∫–∞–∫—É—é –ø–∞–ø–∫—É –±—ã–ª–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                if images_dir.exists() and not assets_dir.exists():
                    target_image_dir = images_dir
                else:
                    target_image_dir = assets_dir
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL
                import re
                match = re.search(r'/([^/]+\.(jpg|jpeg|png|gif|webp))', image_url)
                if match:
                    image_filename = match.group(1)
                    image_file_path = target_image_dir / image_filename
                else:
                    # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º slug
                    image_filename = f"{slug}{image_path.suffix or '.jpg'}"
                    image_file_path = target_image_dir / image_filename
            else:
                log_warning("–®–ê–ì 3: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        else:
            log_info("–®–ê–ì 3: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞—é")
        
        # –°–æ–∑–¥–∞–µ–º HTML —Å—Ç–∞—Ç—å—é
        log_info(f"üìù –®–ê–ì 4: –°–æ–∑–¥–∞–Ω–∏–µ HTML —Å—Ç–∞—Ç—å–∏...")
        html_content, article_url, slug = create_html_article(news_data, web_version, image_url)
        log_info(f"   URL —Å—Ç–∞—Ç—å–∏: {article_url}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML —Ñ–∞–π–ª –≤ posts/ –≤ –ö–û–†–ù–ï —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–Ω–µ –≤ bot/posts/)
        log_info(f"üíæ –®–ê–ì 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HTML —Ñ–∞–π–ª–∞...")
        posts_dir = repo_path / "posts"
        posts_dir.mkdir(exist_ok=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ posts_dir –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤ –∫–æ—Ä–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        if "bot" in str(posts_dir):
            log_warning(f"–®–ê–ì 5: –í–ù–ò–ú–ê–ù–ò–ï: posts_dir –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ bot/: {posts_dir}")
            log_warning(f"   –ò—Å–ø—Ä–∞–≤–ª—è—é –Ω–∞ –∫–æ—Ä–µ–Ω—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...")
            # –£–±–∏—Ä–∞–µ–º bot/ –∏–∑ –ø—É—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            parts = list(posts_dir.parts)
            if "bot" in parts:
                parts = [p for p in parts if p != "bot"]
                posts_dir = Path(*parts)
            log_info(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º: {posts_dir}")
        
        html_file = posts_dir / f"{slug}.html"
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º timestamp –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        if html_file.exists():
            import time
            timestamp = int(time.time())
            html_file = posts_dir / f"{slug}-{timestamp}.html"
            log_warning(f"–®–ê–ì 5: –§–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—é: {html_file.name}")
            # –û–±–Ω–æ–≤–ª—è–µ–º article_url –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ URL
            article_url = f"{SITE_URL}/posts/{html_file.stem}.html"
        
        try:
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            log_success(f"–®–ê–ì 5: HTML —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {html_file.name}")
        except Exception as e:
            error_msg = f"–®–ê–ì 5: –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è HTML —Ñ–∞–π–ª–∞: {e}"
            log_error(error_msg, exc_info=True)
            return None
        
        # –û–±–Ω–æ–≤–ª—è–µ–º sitemap.xml
        log_info(f"üó∫Ô∏è  –®–ê–ì 6: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ sitemap.xml...")
        try:
            update_sitemap(article_url, slug, str(repo_path))
            log_success("–®–ê–ì 6: sitemap.xml –æ–±–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            log_error(f"–®–ê–ì 6: –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è sitemap.xml: {e}", exc_info=True)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º index.html –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        log_info(f"üìã –®–ê–ì 7: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ index.html...")
        try:
            update_index_script = repo_path / "update_index.py"
            if update_index_script.exists():
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç –∏–∑ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
                result = subprocess.run(
                    ["python3", str(update_index_script)],
                    cwd=str(repo_path),
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                if result.returncode == 0:
                    log_success("–®–ê–ì 7: index.html –æ–±–Ω–æ–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
                    if result.stdout:
                        # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞
                        for line in result.stdout.split('\n'):
                            if 'Found' in line or 'Successfully' in line or '‚úì' in line:
                                log_info(f"   {line}")
                else:
                    log_warning(f"–®–ê–ì 7: –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è index.html: {result.stderr}")
            else:
                log_warning("–®–ê–ì 7: –°–∫—Ä–∏–ø—Ç update_index.py –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ index.html")
        except Exception as e:
            log_warning(f"–®–ê–ì 7: –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ index.html: {e}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏—é
        
        # –û–±–Ω–æ–≤–ª—è–µ–º RSS feed
        log_info(f"üì° –®–ê–ì 7.5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è RSS feed...")
        try:
            generate_rss_script = repo_path / "generate_rss.py"
            if generate_rss_script.exists():
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç –∏–∑ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
                result = subprocess.run(
                    ["python3", str(generate_rss_script)],
                    cwd=str(repo_path),
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                if result.returncode == 0:
                    log_success("–®–ê–ì 7.5: RSS feed –æ–±–Ω–æ–≤–ª–µ–Ω")
                    if result.stdout:
                        # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞
                        for line in result.stdout.split('\n'):
                            if 'Found' in line or 'Successfully' in line or '‚úì' in line or 'RSS Feed URL' in line:
                                log_info(f"   {line}")
                else:
                    log_warning(f"–®–ê–ì 7.5: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ RSS feed: {result.stderr}")
            else:
                log_warning("–®–ê–ì 7.5: –°–∫—Ä–∏–ø—Ç generate_rss.py –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é RSS feed")
        except Exception as e:
            log_warning(f"–®–ê–ì 7.5: –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ RSS feed: {e}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏—é
        
        # Git –æ–ø–µ—Ä–∞—Ü–∏–∏
        log_info(f"üì§ –®–ê–ì 8: –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ GitHub...")
        commit_message = f"Add news: {news_data.get('title', '')[:50]}"
        log_info(f"   –°–æ–æ–±—â–µ–Ω–∏–µ –∫–æ–º–º–∏—Ç–∞: {commit_message}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç–∏ —Ñ–∞–π–ª–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        files_to_add = []
        
        # HTML —Ñ–∞–π–ª: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å posts/{slug}.html –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è
        html_file_rel = html_file.relative_to(repo_path)
        files_to_add.append(str(html_file_rel))
        log_info(f"   üìÑ –î–æ–±–∞–≤–ª—è—é –≤ git: {html_file_rel}")
        
        # Sitemap: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å sitemap.xml –≤ –∫–æ—Ä–Ω–µ
        sitemap_file = repo_path / "sitemap.xml"
        if sitemap_file.exists():
            files_to_add.append("sitemap.xml")
            log_info(f"   üó∫Ô∏è  –î–æ–±–∞–≤–ª—è—é –≤ git: sitemap.xml")
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: –µ—Å–ª–∏ –±—ã–ª–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ
        if image_url and 'image_file_path' in locals() and image_file_path:
            try:
                image_file_rel = image_file_path.relative_to(repo_path)
                files_to_add.append(str(image_file_rel))
                log_info(f"   üñºÔ∏è  –î–æ–±–∞–≤–ª—è—é –≤ git: {image_file_rel}")
            except ValueError:
                log_warning(f"–®–ê–ì 8: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞—é: {image_file_path}")
        
        # index.html: –µ—Å–ª–∏ –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω —Å–∫—Ä–∏–ø—Ç–æ–º update_index.py
        index_file = repo_path / "index.html"
        if index_file.exists():
            files_to_add.append("index.html")
            log_info(f"   üìã –î–æ–±–∞–≤–ª—è—é –≤ git: index.html")
        
        # feed.xml: –µ—Å–ª–∏ –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω —Å–∫—Ä–∏–ø—Ç–æ–º generate_rss.py (–≤ public/)
        feed_file = repo_path / "public" / "feed.xml"
        if feed_file.exists():
            files_to_add.append("public/feed.xml")
            log_info(f"   üì° –î–æ–±–∞–≤–ª—è—é –≤ git: public/feed.xml")
        
        log_info(f"–®–ê–ì 8: –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–º–º–∏—Ç–∞: {len(files_to_add)}")
        success = git_add_commit_push(str(repo_path), files_to_add, commit_message)
        
        if success:
            log_success(f"–®–ê–ì 8: –°—Ç–∞—Ç—å—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ GitHub Pages: {article_url}")
            log_info(f"=" * 80)
            log_info(f"‚úÖ –ü–£–ë–õ–ò–ö–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û: {news_title[:60]}")
            log_info(f"   URL: {article_url}")
            log_info(f"=" * 80)
            return article_url
        else:
            log_error(f"–®–ê–ì 8: –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê - –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–æ –ù–ï –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ GitHub")
            log_error(f"   URL —Å—Ç–∞—Ç—å–∏ (–ª–æ–∫–∞–ª—å–Ω—ã–π): {article_url}")
            log_error(f"   –§–∞–π–ª —Å–æ–∑–¥–∞–Ω: {html_file}")
            log_error(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –æ—à–∏–±–æ–∫ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π")
            log_error(f"   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            log_error(f"   - GITHUB_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π")
            log_error(f"   - –ü—Ä–æ–±–ª–µ–º—ã —Å git push (—Å–µ—Ç—å, –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞)")
            log_error(f"   - –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω —Å GitHub")
            return None  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None –µ—Å–ª–∏ push –Ω–µ —É–¥–∞–ª—Å—è - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
            
    except Exception as e:
        error_msg = f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {e}"
        log_error(error_msg, exc_info=True)
        log_error(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏: {news_title}")
        log_error(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {news_url}")
        return None


def submit_to_google_indexing(url: str) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç URL –≤ Google Indexing API –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
    
    –í–ê–ñ–ù–û: –ü—É—Ç—å –∫ –∫–ª—é—á—É –∏—â–µ—Ç—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    –ï—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –∏–∑ bot/, –∫–ª—é—á –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ bot/ –∏–ª–∏ —É–∫–∞–∑–∞–Ω –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å.
    
    Args:
        url: URL —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –∏–Ω–∞—á–µ
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∫–ª—é—á—É
    key_path = Path(GOOGLE_INDEXING_KEY_PATH)
    
    # –ï—Å–ª–∏ –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç
    if not key_path.is_absolute():
        # 1. –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–≥–¥–µ –∑–∞–ø—É—â–µ–Ω —Å–∫—Ä–∏–ø—Ç)
        current_dir = Path.cwd()
        possible_paths = [
            current_dir / key_path,  # –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            current_dir.parent / key_path,  # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–µ—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∏–∑ bot/)
            Path(__file__).parent / key_path,  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–æ–¥—É–ª—è
            Path(__file__).parent.parent / key_path,  # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–æ–¥—É–ª—è
        ]
        
        # –ò—â–µ–º –ø–µ—Ä–≤—ã–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—É—Ç—å
        for path in possible_paths:
            if path.exists():
                key_path = path
                print(f"   üîë –ù–∞–π–¥–µ–Ω –∫–ª—é—á: {key_path}")
                break
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å
            key_path = current_dir / key_path
    
    if not key_path.exists():
        print(f"‚ö†Ô∏è  Google Indexing –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω: {key_path}")
        print(f"   –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—É—Ç–∏:")
        if not Path(GOOGLE_INDEXING_KEY_PATH).is_absolute():
            print(f"   - {Path.cwd() / GOOGLE_INDEXING_KEY_PATH}")
            print(f"   - {Path.cwd().parent / GOOGLE_INDEXING_KEY_PATH}")
            print(f"   - {Path(__file__).parent / GOOGLE_INDEXING_KEY_PATH}")
        print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –≤ Google Indexing")
        return False
    
    try:
        from google.oauth2 import service_account
        from google.auth.transport.requests import Request
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º credentials
        credentials = service_account.Credentials.from_service_account_file(
            GOOGLE_INDEXING_KEY_PATH,
            scopes=['https://www.googleapis.com/auth/indexing']
        )
        
        if not credentials.valid:
            credentials.refresh(Request())
        
        # Google Indexing API endpoint
        indexing_url = "https://indexing.googleapis.com/v3/urlNotifications:publish"
        
        headers = {
            "Authorization": f"Bearer {credentials.token}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "url": url,
            "type": "URL_UPDATED"
        }
        
        response = requests.post(indexing_url, headers=headers, json=payload, timeout=10)
        response.raise_for_status()
        
        print(f"‚úÖ URL –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Google Indexing: {url}")
        return True
        
    except ImportError:
        print("‚ùå google-auth –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install google-auth")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Google Indexing: {e}")
        return False
